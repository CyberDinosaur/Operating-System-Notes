# 一.同步问题的背景

## 1.多核场景

新世纪之前，CPU性能的提升主要是靠提高单核的运行频率，然而这种方法撞上了功耗墙，所以多核开始逐渐流行起来。

但是很多时候并不是“人多力量大”，操作系统在多核场景下会面临两个问题：

* **正确性保证**（本章重点）

  多核的任务处理具有较高的并行性，其可能会导致多个任务对于某一共享资源的竞争。为了保证共享资源状态的正确性，OS需要正确地在这些子任务间进行**同步**。

  > 同步原语其实并非多核时代的产物，单核中也存在多个线程之间的同步需求。这主要是由于调度器可以调度不同的线程交错执行，产生“假并行”的效果。

* **性能保证**（后面再讨论）

  多核多处理器带来了新的硬件特性，可扩展性问题有可能会导致性能断崖。应当如何利用多核的硬件特性？

<img src="图片\同步原语02.jpg" style="zoom:80%;" />

## 2.生产者消费者模型

### （1）单生产者&单消费者

为了保证正确性，只需要设置两个计数器标记缓冲区已填充的数据个数与空余位置个数，从而避免可能的越界即可。

> 两个计数器的更新操作还要默认是原子的。

```c
volatile int empty_slot = 5; // 共享的
volatile int filled_slot = 0;// 共享的
void producer(void) {
	int new_msg;
	while (TRUE) {
		new_msg = produce_new();
		while (empty_slot == 0) 
			; // 没有空位可使用
		empty_slot--;
        
		buffer_add(new_msg);
        
		filled_slot++;
	}
}
void consumer(void) {
	int cur_msg;
	while(TRUE) {
		while(filled_slot == 0)
			; // 没有对象可消耗
		filled_slot--;
        
		cur_msg = buffer_remove();
        
		empty_slot++;
		consume_msg(cur_msg);
	} 
}
```

### （2）多生产者&单消费者

由于“生产”和“消费”这两个行为都默认是原子的，所以在两个计数器的帮助下就可以实现协同工作而不产生错误。

对于多生产者、单消费者的场景，即使更新操作是原子的，但是由于其尝试同时对共享缓冲区进行操作，会产生竞争冒险：

* 数据覆盖

* 程序计数出现问题

<img src="图片\同步原语01.jpg" style="zoom:80%;" />

我们可以通过延迟生产者2的执行时间来避免这些问题，但是延迟代价很大，近似为生产者之间顺序运行，“多核”形同虚设。

## 2.临界区问题

对于多生产者/单消费者模型中出现的**竞争冒险**问题，也即有多个平级的用户同时申请某一共享内存区域的资源的场景下可能会产生的问题。我们的解决方案一般是设置**临界区**，也即保证**互斥**（某一时间只能有一个平级用户进入）访问共享资源的代码区域。

所以我们现在的任务（也是这一章的重点）就变成了如何设置协议来保证临界区访问的互斥性，称为临界区问题。

###（1）问题抽象

<img src="图片\同步原语11.jpg" style="zoom:80%;" />

临界区部分中的代码根据问题描述应当满足三个条件

*  **互斥访问(mutual exclusion)**：同一时刻，最多只有一个线程进入临界区。
*  **有限等待**：当线程申请进入临界区时，必须在有限时间内获得许可，也即线程等待的时间是一定的。
*  **空闲让进**：没有线程在临界区时，必须选一个线程允许其进入临界区。

### （2）问题解决——硬件方法(单核)

解决临界区问题是保证并行场景下程序运行正确性的关键。

对于单核架构下的“假并行”，我们可以通过硬件设置一个简单的算法来解决这个问题——**关闭中断**。

单核中的控制流在本质上来讲是一维的，线程在调度器分配的时间片上运行，而线程之间的抢占式转换是通过中断实现的（正在运行的线程被OS强行转换为阻塞状态，是为中断）。

所以如果我们使得**线程在进入临界区之间关闭中断**，其在临界区内的运行就不可能被其他线程抢占，直至自身运行完毕退出临界区，中断关闭。

> 这种关闭中断的方式在多核场景下是无法产生作用的，原因在于中断是受本地调度器控制的，各个本地调度器之间缺乏有效的信息来避免抢占。

接下来我们主要会基于多核的场景，讨论如何解决临界区问题。

#二.软件方法：皮特森算法

关键点在于两个全局变量：

* 布尔数组flag[]：对应位为TRUE, 表示该线程申请进入临界区。
* 变量turn：裁决谁可以进入临界区，数字1表示线程1进，0表示线程0进。

<img src="图片\同步原语12.jpg" style="zoom:80%;" />

各线程首先标定flag数组，表明自己申请进入临界区，但是之后将turn设置为对方的编号，这样做能够保证：如果竞争线程没有声明要进入临界区，自己可以直接畅快的进入临界区运行；如果竞争线程也声明了要进入临界区，线程在运行完这条语句之后的瞬间一定会阻塞在循环语句上。

第一种情况不存在竞争冒险；第二种情况，对于首先跑到循环语句阻塞的线程，在对方运行完设置turn的语句进入阻塞状态时，自身的阻塞状态自动被解除，进入临界区。运行完之后设置flag为False，对方就可以结束阻塞，进入临界区。

> 互斥访问和空闲让进显然能够满足，对于有限等待，在临界区长度有限的情况下，如果线程0在刚走出临界区之后继续申请（线程1正在阻塞），其也不会成功，因为某种程度上线程1比它“先到”，所以会“先得”，不会出现无限等待的情况。

> Micha Hofri与1990推广了皮特森算法，使其能够被用于任意数量的线程，而非原本的双线程。
>
> 皮特森算法**要求读取操作严格按照程序顺序执行**，但现代CPU一般都有乱序执行机制，而且编译器也有可能会将原程序的顺序打乱，所以皮特森算法不太够用了。

# 三.软硬件协同：互斥锁

##1.原子操作（硬件）

原子操作：不可被打断的一个或一系统操作。

我们通过观察发现，多生产者/单消费者模型中产生错误的根本原因在于某个线程的读写过程被打断了，这也就是我们为什么如此执着于解决临界区问题的原因。

<img src="图片\同步原语13.jpg" style="zoom:50%;" />

> 上图实际上就展示了读写操作非原子性所导致的正确性问题产生的症结：如果写操作是依赖于读操作的，进程②就会产生更新遗失(lose update)。

所以我们想，是否可以**基于硬件所提供的某些现有原子操作，来实现临界区的互斥**呢？

常见硬件原子操作：

* 比较与置换（Compare-And-Swap, CAS）

  就是对比某内存空间上的值与期待值，如果两者相等就改写内存空间上的值。

  ```c
  int CAS(int *addr, int expected, int new_value) {
  	int tmp = *addr;
  	if(*addr == expected) 
  		*addr = new_value;
  	return tmp; 
  }
  ```

* 拿取与累加（Fetch-And-Add, FAA）

  就是将某特定值累加到某地址空间上。

  ```c
  int FAA(int *addr, int add_value) {
  	int tmp = *addr; 
      *addr = tmp + add_value;
  	return tmp;
  }
  ```

> 上面的代码只是指示一种逻辑，其本身并不是原子操作，真正的原子操作是由硬件支持的。
>
> 在Intel平台，原子操作主要是由**锁总线**实现的（对任意地址的修改都要经过锁总线，所以控制锁总线可以轻易保证对内存空间操作的原子性）。
>
> 在ARM平台，采用**Load-Link/Store-Conditional(LL/SC)**来实现。其本质逻辑就是，在读的时候安一个监控器，在写的时候进行检查，保证两个时刻的值一致，否则就重新去读。

##2.互斥锁抽象

互斥锁的抽象十分简单，就是一把锁在同一时刻只能被一个线程拥有，当锁被占有时，其他线程只能等待锁被释放。对于临界区问题，我们可以在进入临界区之前规定线程必须获得某个锁，在退出临界区时把锁释放。这样做就能满足临界区的是三个条件。

```c
volatile int buffer_write_cnt = 0;
volatile int buffer_read_cnt = 0;

lock_t buffer_lock;  //锁变量
int buffer[5];

void buffer_init(void) {
	lock_init(&buffer_lock);
}

void buffer_add_safe(int msg) {
	lock(&buffer_lock);
	buffer[buffer_write_cnt] = msg;
	buffer_write_cnt = (buffer_write_cnt + 1) % 5;
	unlock(&buffer_lock);
}

int buffer_remove_safe(void) {
	lock(&buffer_lock);
	int ret = buffer[buffer_read_cnt];
	buffer_read_cnt = (buffer_read_cnt + 1) % 5;
	unlock(&buffer_lock);
	return ret;
}
```

现在问题的关键就变成了，如何在硬件所提供的原子操作的基础上，保证锁的获得是互斥的？

###（1）自旋锁(CAS)

自旋锁用一个变量lock表示锁的状态，0表示空闲，1表示锁已经被占有。

各个线程使用循环CAS验证条件的方式（有点类似于轮询）请求锁，由于CAS是原子的，所以某一时间只能有一个线程进入临界区。

```c
void lock_init(int *lock) {
	// 初始化自旋锁
	*lock = 0; 
}
void lock(int *lock) {
	while(atomic_CAS(lock, 0, 1) != 0)
	; //说明锁值为1，需要死循环忙等
}
void unlock(int *lock) {
	*lock = 0; 
}
```

CAS虽然简单易懂，**效率高响应快**但是其**不能保证有限等待**（皮特森算法就可以）。原因在于，除了第一轮之外，申请顺序与谁是下一个锁拥有者无关，所有竞争者将在同一时间尝试进行原子操作，成功与否完全取决于硬件特性。

###（2）排号自旋锁(FAA)

排号自旋锁就是为了解决上面的问题，其锁变量不再只是单纯的一个布尔值，表征当下锁是否空闲。而是一个包含两个变量的结构体，表示现在的拥有者是谁，以及下一个待分配的拥有者编号是谁。

**竞争公平性——先到先得**

```c
struct lock {
	volatile int owner;
	volatile int next;
};

void lock_init(struct lock *lock) {
	// 初始化排号锁
	lock->owner = 0;
	lock->next = 0;
}

void lock(struct lock *lock) {
	// 拿取自己的序号
	volatile int my_ticket = atomic_FAA(&lock->next, 1);
	while (lock->owner != my_ticket)
		; // 循环忙等
}
void unlock(struct lock *lock) {
	// 传递给下一位竞争者
	lock->owner++;
}
```

# 三.条件变量

##1.引入

对于上面的几种临界区问题解决方案，我们对于临界区之外的线程采取**循环忙等**的方式，其并没有产生任何效能，但是却不断在消耗CPU资源，这是我们不想看到的。

条件变量提供一种接口，使得线程可以停止使用CPU并将自己**挂起**，当等待条件满足时，其它线程会**唤醒**该挂起的线程让其继续执行。

## 2.条件变量的使用

由于条件变量本身并不提供互斥的临界区操作，所以其**一定要搭配互斥锁一起使用**：

<img src="图片\同步原语15.jpg" style="zoom:80%;" />

<img src="图片\同步原语14.jpg" style="zoom:80%;" />

* 对于两个共享计数器empty_slot/filled_slot，分别使用两个不同的互斥锁empty_cnt_lock/filled_cnt_lock进行保护。
* 创建了两个不同的条件变量empty_cond/filled_cond，分别对应“缓冲区无空位”(生产者)和“缓冲区无数据”(消费者)。

> ①为何依旧采用循环等待的方式？这是要防止在一方在满足条件放锁、并尝试唤醒另一方的过程中时，有的线程会趁着这段权力真空，迅速拿锁并消耗资源，这时被唤醒的线程如果不进行条件判断直接冲，就会造成共享内存区出现异常。
>
> ②为何要同时挂起与放锁（一般需要OS协助完成）？因为如果先挂起再放锁，睡着的线程将无法完成放锁操作；如果先放锁再挂起，就会产生临界区的真空，有可能会出现另一方在这个空档调用cond_signal，使得唤醒信号放空，挂起的线程将一睡不醒。
>
> ③为何不在empty_slot/filled_slot为0的时候，才会进行唤醒操作？虽然看起来只有在上面两种情况才会出现生产者/消费者等待在该条件变量上，故而需要调用cond_signal的操作。但事实上，当empty_slot/filled_slot为0的时候，可能有多个生产者/消费者等待在条件变量上，故而如果只在这个时刻有多个线程到达，唤醒等待线程，有可能只会唤醒一个，之后就会出现剩余资源与等待线程数量不匹配的现象。

## 3.条件变量的实现

<img src="图片\同步原语16.jpg" style="zoom:80%;" />

> 我们可以看到，一般的唤醒操作都是非广播式的。

# 四.信号量

##1.引入

上面的借由条件变量提高的互斥锁看起来已经非常完美了，但是还有个问题：**设置的变量结构体太多了**——两个管理共享内存区的计数器，两把保证共享计数器修改互斥的锁，两个临界区等待位置的条件变量（而且这个条件变量的定义与条件声明还是分开的）。

由信号量提供的接口则是**直接根据共享资源的情况（将共享资源的状态封装为一个统一的变量），决定不同的线程是应当执行还是等待**。

其相当于协调不同线程之间的信号灯，辅助控制多个线程访问有限数量的共享资源，使用**PV原语**控制执行/等待。

<img src="图片\同步原语17.jpg" style="zoom:80%;" />

* P（wait）：当信号量 ≤ 0 时循环忙等。
* V（signal）：当信号量 ＞0 时增加信号量的值供wait的线程使用。

##2.信号量的使用

<img src="图片\同步原语18.jpg" style="zoom:80%;" />

只使用共享资源作为参数，并且只允许wait、signal、初始化三个操作对其进行修改。

## 3.信号量的实现

<img src="图片\同步原语19.jpg" style="zoom:80%;" />

我们发现信号量的这两个接口实际上就相当于完成了对由条件变量升级后的互斥锁的进入临界区和退出临界区这两个操作流程的封装and对共享内存区资源进行了细化以使各种变量能够统一。

* 首先是对于共享资源区的细化：

  value＞0：表示剩余资源数量

  value ≤ 0：表示等待在此共享区的线程数量

  wakeup为正数，表示有线程等待时的可用资源数量。

* 封装操作大体一致：加锁、修改共享区、放锁。由于信号量对参数进行了整合，所以会有一些不同：

  * 首先修改value的值，然后如果value＞0表示资源有盈余，直接放锁完成操作；
  * 否则就需要进行与wakeup相关的中间态操作：消费者首先利用条件变量循环等待，直到被唤醒才去消耗wakeup的资源；生产者首先增加wakeup资源，之后进行唤醒操作。

> 之所以条件变量的等待使用do while语句，是为了保证**有限等待**：与皮特森算法有异曲同工之妙，想申请资源，首先进入睡眠等待，防止某个贪心线程不会在调用signal之后立刻自产自销、抢占资源。
>
> srds这种操作也无法保证资源的分配顺序是根据wait次序来先到先得的，signal信号发起的那一刻，所有正在到等待的线程都是平权的。

# 五.读写锁

> 有空再写

# 六.同步原语产生的问题

## 1.死锁

### （1）死锁产生原因

<img src="图片\同步原语03.jpg" style="zoom:80%;" />

###（2）死锁问题解决

####①出问题再处理：死锁的检测与恢复

OS维护资源分配表与线程等待表，通过这两张表就可以唯一确定系统内部的资源分配图。

通过检查这个图中是否存在环可以检测是否产生了死锁。

<img src="图片\同步原语04.jpg" style="zoom:80%;" />

死锁产生后的恢复：

* 直接kill所有循环中的进程

* Kill一个，看有没有环，有的话继续kill
* 全部回滚到之前的某一状态

#### ②设计时避免：死锁预防

可以针对四个方向分别避免。

1.  **避免互斥访问：通过其他手段（如代理执行）**

   <img src="图片\同步原语05.jpg" style="zoom:80%;" />

   缺点是大部分程序都不太容易修改为这种模式。

2. **不允许持有并等待：必须一次性申请完毕**

   ```c
   while(true) {
   	if(trylock(A) == SUCC) { 
   		if(trylock(B) == SUCC) {
   			// 临界区代码
   			// ...
   			unlock(B);
   			unlock(A);
   			break;
   		} 
      		else {
   			unlock(A); 
   		} 
   	} 
   }
   ```

   要成功就都成功，否则就一个也不要。

   虽然这种情况能够成功避免死锁，但是如果运气不好可能会出现“活锁”的现象，空占用资源，而什么都没干。

   <img src="图片\同步原语06.jpg" style="zoom:80%;" />

3. **资源允许抢占：需要考虑如何恢复**

   就是让死锁的其中一个线程先回滚，让另一个线程得到资源并运行（强行把一个线程顶回去）。

   但是由于这个方法需要尽量保存程序运行每一步的状态，所以只适用于易于保存和恢复的场景。

4. **打破循环等待：按照特定顺序获取资源**

   就是打破循环等待，对所有资源进行编号，根据编号的优先级依次获取资源，避免产生同时卡死的现象。

####③运行时避免死锁：死锁避免

由Dijstra设计的**银行家算法**：

由前面的讨论我们可以获得一点启发——按照特定的顺序获取资源就可能不死锁，这种不死锁的调用顺序就是**安全序列**。

为了找到一个安全序列，所有进程获取资源都需要先征求**管理者**的同意，管理者会预演执行这个进程的请求。如果会发生死锁，则阻塞这个进程的请求；否则，就分配资源给进程，让其运行。

管理者会维护一个临时数组，用来模拟执行过程中可用的资源数量。

<img src="图片\同步原语07.jpg" style="zoom:80%;" />

* 如果模拟某个线程的运行，发现资源不足，就阻塞之。

* 如果模拟某个线程的运行发现资源足够，就让其运行，并且在它运行完成之后，回收其所占有的资源。

* 如果强行分配资源——产生死锁

  <img src="图片\同步原语08.jpg" style="zoom:80%;" />

## 2.活锁

不允许持有并等待的情况下，也即要申请资源只能一次性全部获得，要么全拿要么一个不要，这种情况实际上就是要求在共享资源产生冲突的时候，双方都放弃对资源的使用。

其虽然能够有效避免死锁，但是会导致双方不断重复尝试申请，持续消耗资源而不输出有效价值的“活锁”。

不过活锁大概率可以自行消除，所以一般不需要专门为其设置相关策略。

## 3.优先级反转

<img src="图片\同步原语09.jpg" style="zoom:80%;" />

如果高优先级在运行的时候，需要某个共享资源，但是共享资源已经被其它低级线程互斥占有，高优先级的线程只能进入互斥等待状态，此时较低优先级的线程会先执行。

我们可以通过**优先级继承**的方式来解决这个问题：高优先级如果在请求共享资源的时候被阻塞，就先把自己的优先级给占有锁的线程，等它运行完自己再运行。

<img src="图片\同步原语10.jpg" style="zoom:80%;" />



















