# 一.概述

## 1.为什么需要虚拟内存？

根据冯诺依曼架构，计算机中的大部分元件都是无状态的，只有存储器和少量的寄存器可以存储状态，换句话来讲，如果你能控制计算机的存储器，你就控制了一台计算机的控制权。所以说内存管理至关重要。

那么怎样管理内存呢？

* 独占内存模式：应用程序运行时，允许它占有所有内存，切换应用程序的时候将之前应用程序的状态换出到磁盘即可。
* 划分内存模式：让每个应用程序独立地使用内存的一部分。

独占模式显然不靠谱，而划分内存模式也有很多问题，比如难以保证应用程序之间的边界(恶意越界)、无法保证应用程序可用的地址空间是连续的和统一的。

故而我们选择在应用程序与物理内存之间增加一层由OS管理的抽象——**虚拟内存**。其就相当于一层模拟的内存空间，是操作系统提供给用户的一层服务，具体物理内存的管理和分配由OS来进行。

虚拟内存的优点：

* 由OS统一管理物理内存，**提高内存资源的有效利用率。**
* 增强应用程序之间的**隔离**，提高安全性。
* 利用OS提供的虚拟内存**服务**，应用面对的内存是统一、连续的，而且大于真正的物理内存，减轻了编程的压力。

## 2.虚拟内存的机制

<img src="图片\内存管理01.jpg" style="zoom:80%;" />

实际上，我们要关注的重点主要是：MMU中的**地址翻译**是如何进行的（虚拟地址和物理地址之间的映射关系是怎样的）？其中又会涉及地址翻译机制的空间结构如何优化（多级页表）？地址翻译的时间性能如何优化（TLB）？

我们首先介绍虚拟内存的组织架构是怎样的，也即地址映射关系建立的机制是什么？

### （1）分段

虚拟地址空间被分成**若干个大小不同的段**，物理内存同样以段为单位进行对应分配。虚拟空间相邻的段对应的物理空间的段不一定相邻，但是段内一定连续。

CPU首先把虚拟地址（结构为段号+段内地址）交给MMU，之后MMU通过段表寄存器查到段表的位置，然后利用段号找到段表中对应的段，在加上段内地址偏移量就可以找到虚拟地址对应的物理地址。

<img src="图片\内存管理02.jpg" style="zoom:80%;" />

段表的问题在于段的粒度的粗细不受控制，容易在段与段之间留下碎片空间，也即**外部碎片**，降低主存的利用率。

###（2）分页

为了解决分段机制的外部碎片问题，分页机制采取的更细粒度、更规整的内存管理：

* 虚拟地址空间和物理内存都被划分为连续、等长的页。
* 任意虚拟页可以映射到任意物理页。

虚拟地址的格式类似为：**虚拟页号+页内偏移**。

虚拟页号到物理页号的映射关系主要存储在**页表**中（页表起始地址对应保存在页表基地址寄存器中），页表主要由OS来进行管理。

> 页表实际上是页表项的集合，每个页表项对应一个由虚拟页到物理页的映射。

# 二.分页机制优化

## 1.空间结构——多级页表

###（1）为什么需要多级页表？

前面我们采用的是单级页表，其实际上就相当于一个大数组。假设虚拟地址空间为64位，页大小为4K，页表项的大小为8字节，我们可以得到单级页表的大小为： $2^{64} / 4K * 8 = 33,554,432 GB$ ！这样的开销对于中间层抽象来说无异于“捡了芝麻，丢了西瓜”。

单级页表之所以空间消耗这么大，是由于其要求整个页表在物理内存中必须连续，没有用到的数组项（映射关系）也要预留着，也即数组内部不允许留有空洞。

为了压缩页表的大小，我们引进了多级页表结构。

###（2）AArch64的4级页表：

####①虚拟地址(64bits)的结构：

* 63-48位：硬件要求全为0或1（应用程序一般是全为0）。这也就意味着应用程序的虚拟空间大小只有48位。
* 11-0位：由于页的大小是4KB，所以前12位表征页内偏移量。
* 虚拟页号只有36位，也即只能存储 $2^{36}$ 个页表项。我们平均分成4份，每份9位，每份可以指向512个页表项。
  * 47-39：0级页表的虚拟页号
  * 38-30：1级页表的虚拟页号
  * 29-21：2级页表的虚拟页号
  * 20-12：3级页表的虚拟页号

#### ②多级页表工作原理：

多级页表实际上就像是字典树，其从0级页表开始一次往下寻找，直到终点（终点不一定是3级页表，有可能在之前就停止了）。

0级页表的基地址存储在**页表基地址寄存器**中，而且0级页表只有1个，包含512个页表项，所以0级页表在存储中本质上就是一个页的大小。可以通过0级页表的虚拟页号迅速查找到“页表项”，L0页表项存储对应1级页表的基地址...

> 页表基地址寄存器有两个：TTBR0_EL1 & TTBR1_EL1，前者用来保存应用程序的页表，后者用来保存操作系统的页表（OS本质上也不过是一个特权级更高的应用程序而已，所以也需要占有一定的物理内存，需要页表来存储虚拟空间到物理内存的映射关系）

<img src="图片\内存管理03.jpg" style="zoom:80%;" />

值得注意的是，虚拟地址本身结构没有变化，结构内的虚拟页号和页内偏移甚至也可以没有变化，我们所做的不过是对虚拟页号进行了划分，多级页表不过是一种更高效的转化虚拟页号至物理页号的方式。

#### ④多级页表的缺点

多级页表是典型的用**时间换空间**的设计，虽然减小了页表所占空间，但是使得MMU在翻译地址的过程中需要一次查找多个页表页中的页表项，一次地址翻译可能会导致多次物理内存访问，耗时较大。

问题来了，如何降低地址翻译的开销？

## 2.时间性能——TLB

###（1）过程

我们可以利用转址旁路缓存TLB来缓存虚拟页号到物理页号的映射关系。如果命中，就不再查询页表；未命中，才会查询页表。

<img src="图片\内存管理04.jpg" style="zoom:80%;" />

###（2）结构

TLB位于CPU之内，CPU核心之外。按照缓存结构，TLB通常也采用分级设计。

<img src="图片\内存管理05.jpg" style="zoom:80%;" />

> TLB的管理：
>
> * 在AArch64和x86_64中，TLB由硬件MMU直接管理。
>
> * 在一些体系结构（如MIPS）中，TLB由软件进行管理
>
>   TLB未命中时会触发异常交由OS进行负责。优势是灵活性，缺点是会加重软件的设计成本和性能负担。

### （3）TLB刷新

在页表发生变化的时候（应用程序切换导致页表基地址变化等原因），TLB也要进行同步更新。

对于因为应用程序切换导致页表基地址所发生的变化，我们需要主动刷新TLB。

但是TLB每次全部刷新势必会造成应用程序开始产生大量命中缺失，我们可以通过为不同的应用程序打上不同的**标签**（ASID、PCID），在刷新的时候选择性的刷新即可：

* 刷新全部TLB
* 刷新指定ASID的TLB
* 刷新指令虚拟地址的TLB

> 系统调用（应用程序和OS之间的切换）的过程中不会产生TLB刷新：
>
> * 对于AArch64体系结构，提供了两个不同的页表寄存器，所以在系统调用的时候不需要切换页表，故而可以避免TLB的刷新。
> * 对于x86-64体系结构，虽然只有一个页表基地址寄存器，但OS不使用单独的页表，而是把自已映射到应用程序页表的高地址部分，在系统调用中同样不发生变化。

# 三.页表管理

前面我们实际上介绍完了虚拟内存的内部机制与优化，也即虚拟地址怎样高效的转化成物理地址。但虚拟内存只是空中楼阁，真正让它起作用的是物理内存，所以我们势必要讨论OS该如何分配宝贵的物理内存给虚拟内存，也即OS对页表的管理？

## 1.换页机制

由于我们实现的虚拟内存是大于真实的物理内存的，所以当出现物理内存不够用的时候，OS会把某些物理内存页**换出**到磁盘等外部存储设施中，并且删除程序页表上对应的映射页表项。

当应用程序访问这些物理内存页所对应的虚拟内存时（此时就是已分配但是未映射到物理内存的虚拟页），由于在页表中找不到对应的映射，就会触发**缺页异常**。

此时CPU就会运行OS预先设计好的**缺页异常处理函数**，找到一个“空闲”的物理内存页，将磁盘上的数据内容**换入**到物理页中，并在页表中填写虚拟地址到这一物理页的映射。

<img src="图片\内存管理06.jpg" style="zoom:80%;" />

> 按需分配机制：
>
> 换页机制不仅在请求的内存大于物理内存量的时候有用，在某应用程序预先申请大量内存的时候也用得到。此时我们可以先给它画个饼，将一定量的虚拟内存标定为已分配未映射的状态，等到应用程序真正需要的时候再给它分配物理内存页。

##2.换页机制的优化

优势：节约内存资源。

劣势：缺页异常会导致访问延迟增加。

我们发现缺页异常是影响性能的关键因素，所以我们的优化点将集中在如何减小缺页异常发生的次数上。

* 优化换入策略：采用**预取机制**（Prefetching），在换入的时候利用时空局部性预测那些页即将被访问，将它们一并换入。
* 优化换出策略：在选择将哪些物理页换入到磁盘上时，尽量选择代价最小的**页替换策略**。

## 3.页替换策略

### （1）MIN策略

又称OPT策略，是理想化的最优页替换策略。

优先选择将未来不会再被访问的页、或者**最长时间内不再被访问的页换出**。

由于应用程序的行为具有一定的随机性，我们很难根据现有的信息精准预测出某个页下一次被访问的时间，故而MIN策略一般不可达，但是其为我们设计其它策略指明了方向——替换优先级与下一次被访问的时间呈正相关。

### （2）FIFO策略

优先选择最先换入的页进行换出。

也即按照页换入的顺序维护一个队列，新换入的页进入队尾（等着被枪毙），每次换出（枪毙）队头的页。

本身很简单、时间开销低，但是由于其隐含的逻辑是先进来的页，距离下一次被访问的时间更长，概率相关性较小，故而效果很差。

### （3）Second Chance策略

FIFO策略的改进版。如果某次访问时，要访问的页在队列中，就给这个页加上一个**标记**。当此页处于队头要被枪毙的时候，标记可以当做免死金牌，让它又重头再来的机会，可以重新回到队尾，并且顺序检查下一个队头元素。

### （4）时钟算法

Second Chance策略的改进，将队列变为环形队列。

设置一个指针指向队列的队头，也即新换入页的后一个。每次检查换出就从这个指针开始，如果当前页有免死金牌标记，就将标记位清零并把指针顺时针移到下一个页，如此直到找到一个可以换出的页。

### （5）LRU策略

**选择最久没有被访问的页。**（假定越长时间没有被访问，其被访问的频率就比较低，以后也不太可能会被频繁访问）

通过维护一个链表，记录访问过程，新访问的会移到尾端，每次换出选择头部的页进行换出。

### （6）MRU策略

**选择最近被访问的页**。（假定程序不会再次访问短时间内被访问过的页，好马不吃回头草）

# 四.虚拟内存功能

## 1.共享内存

共享内存就是让一个**物理内存页在不同的应用程序间共享**。其可以通过让不同程序的某段虚拟内存映射到同一片物理内存区间上来实现。

利用共享内存，我们可以实现进程间通信，以及写时拷贝、内存去重等内存管理功能。

### （1）写时拷贝（copy-on-write）

场景：

* 不同应用程序之间有很多共同的内存数据（比如加载了相同的动态链接库等），此时该如何高效利用内存资源呢？
* 如何利用fork中初始状态下父子进程的内存数据和地址空间完全相同的特点来高效实现这种机制呢？

**写时拷贝机制：**

<img src="图片\内存管理07.jpg" style="zoom:80%;" />

* 允许不同应用程序以**只读**的方式共享同一段物理内存。
* 一旦某个应用程序尝试对这段内存进行修改，就触发**缺页异常**，但是此时的缺页异常是因为应用程序违反其自身的权限所导致的。
* 在触发缺页异常后，CPU同样会将控制流交给**缺页异常函数**。在函数中，OS会发现触发缺页的原因是应用程序尝试修改自身只有只读权限的内存，而且相应的内存区域还是被OS标记为写时拷贝的。
* 此时OS就会将缺页异常对应的物理内存页重新拷贝一份，并**将新拷贝的物理页以可写可读的方式重新映射给触发异常的应用程序**，之后就恢复应用程序的执行。

> 应用程序对于某段内存空间的权限是如何实现的呢？
>
> 页表中的页表项除了存储的对应的物理内存地址（47-12），剩下的位还包含了别的信息，比如标识虚拟页的权限（是否可写、可执行）的权限位。

### （2）内存去重

基于写时拷贝机制，OS可以定期在内存中扫描具有相同内容的物理页，并且找到映射到这些物理页的虚拟页。只保留一个物理页，让其它虚拟页都以写时拷贝的方式映射到这个物理页上。如Linux的KSM。

不过这样做会对应用程序的访问延迟造成影响（缺页异常+内存拷贝），这其实也体现出写时拷贝是一个**时间(possible)换空间**的做法。

> 内存去重也有可能会带来一定的安全问题：攻击者可以通过穷举的方式不断构造数据，之后通过测试延迟猜测系统内有没有重复的数据，从而产生数据泄露。

## 2.内存压缩

OS可以将一些最近不太会使用的内存页进行压缩，从而释放内存空间。

* Windows 10

  压缩后的数据仍然存放在内存中，当访问被压缩的数据时，操作系统将其解压即可

  对比交换内存页到磁盘，内存中的压缩/解压操作显然时延更短，所以节省了时间。

* Linux

  zswap区域：换页过程中磁盘的缓存

  将准备换出的数据压缩并先写入 zswap 区域 （内存）。如果短时间内会再次访问直接解压即可，一段时间后将区域内的压缩内存页统一换出到磁盘。

  这样做一方面减少甚至避免了磁盘I/O，而且能够提高磁盘I/O的效率。

## 3.大页

前面介绍的优化地址翻译时间性能的结构TLB实际上还有个问题——**TLB缓存项太少了**。这就衍生出一个问题，即如何尽量减少TLB缓存项的使用？

我们之前提到过，在多级页表结构中，其未必一路映射到L3，而是有可能在L1、L2就找到物理内存页的起始地址了，这就是所谓的**大页**。

页表项通过第一位标志位来判断映射是否终止，也即此页表项所映射到的是不是大页。（0是大页，1不是）

<img src="图片\内存管理08.jpg" style="zoom:80%;" />

<img src="图片\内存管理09.jpg" style="zoom:80%;" />

> **大页的大小**实际上就是此级页表的页表项个数乘以目标页的大小。
>
> 比如在L4体系中，如果物理页的大小是4K（默认页表项大小为8字节），也就意味着每个页表页有512个页表项，则L2大页为2M，L1大页为1G。
>
> 如果物理页的大小是16K，每个页表页共有2048个页表项，则L2的大页为32MB；如果物理页的大小为64K，同理L2大页为512MB。（ARMv8体系结构中，当时用16KB或64KB大小的物理页时，只有L2有大页）。

**大页的利弊：**

好处：

* 减少TLB缓存项的使用，提高TLB的命中率。
* 减少了页表的级数，提升页表的效率。

坏处：

* **内部碎片**：未使用整个大页会造成物理内存资源浪费。
* 增加管理内存的复杂度。

案例：Linux系统中提供API给应用程序进行显式的大页分配，以及透明大页机制自动将4K的物理页合并成2M的大页。

# 五.物理内存分配器

我们前面研究了虚拟内存借助页表向物理内存页的翻译过程，以及页表中映射关系的管理。其中后者虽然是管理映射关系的，但是难免也会涉及到OS对物理内存的利用，比如有个虚拟内存映射请求，我们应当选择哪个物理内存？物理内存空间不足应当换出哪个物理页？（已经讨论过了）...以求能够达到对有限物理内存资源的高效利用。

由于物理内存的硬件细节实际上是比较复杂的，所以OS在使用以及管理物理内存的时候，并不是直接对其进行操作，而是要借助**内存管理器（Memory Controller）**提供的封装服务。其将物理内存封装为一个可逐字节寻址的“大数组”，是OS对物理内存的使用管理变得更加简单。

OS的物理内存分配器就是再此基础之上构建的。

## 1.目标与评价维度

* **更高的内存资源利用率。**

  也即应当尽量减小内存碎片的存在。

  * 外部碎片：空闲的但不连续，无法被使用。

    一般产生于多次分配和回收之后，本质原因在于内存分配的规划不合理（过于混乱、自由与随机）。

    <img src="图片\内存管理10.jpg" style="zoom:80%;" />

  * 内部碎片：分配大小大于实际需要。

    产生的根源在于内存分配的规划归于统一、固定与死板。

    <img src="图片\内存管理11.jpg" style="zoom:80%;" />

* 物理内存分配器要追求更好的性能，要尽可能的降低其本身的分配延迟以及占用的CPU和存储资源。

## 2.伙伴系统

以“块”为单位，分配连续的物理内存页。各个块的大小可以不同，由一个或几个连续的物理页组成，但是物理页的数量必须是2的n次幂。

<img src="图片\内存管理12.jpg" style="zoom:80%;" />

当收到对块的请求时，伙伴系统会从小到大逐次查找空闲的块，直到找到最接近要求大小的块。如果此空闲块过大可以进行分裂，分裂出来的两个块互为伙伴。

当要释放空闲的块时，需要检查其伙伴是否空闲，如果空闲则两者合并成更大的块；否则级联进入相应的数组位置。

PS：空闲的块怎么管理？——**链表数组**

> 如何判断两个块之间是否为伙伴？
>
> 由于伙伴之间的物理内存是相邻的，所以块A的首地址+A的大小=块B的首地址。
>
> 也即两个块的物理起始地址只有一位是不一样的，这个位由前面的块的大小决定（实际就是前块大小的位数）。所以伙伴之间的确认十分高效。

<img src="图片\内存管理13.jpg" style="zoom:80%;" />

<img src="图片\内存管理14.jpg" style="zoom:80%;" />

<img src="图片\内存管理15.jpg" style="zoom:80%;" /><img src="图片\内存管理16.jpg" style="zoom:80%;" /><img src="图片\内存管理17.jpg" style="zoom:80%;" />

伙伴系统的块分裂与合并操作都是级联的，因此能够很好的**解决外部碎片的问题**。

## 3.SLAB分配器

伙伴系统虽然能够较好的解决外部碎片的问题，但是由于其最小分配单位是一个物理内存页（4KB），而内核中需要分配的内存大小（OS里面结构体的大小）通常为几十、几百字节。故而会产生**较为严重的内部碎片问题**。

SLAB分配器家族 (Linux)

* SLAB分配器

* *SLUB分配器：复杂度降低且性能提高。

* SLOB分配器：存储开销小，适合嵌入式设备。

SLAB分配器的目标就是**能够快速分配小内存，缓解内部碎片问题**。

###（1）SLAB分配器的策略

观察发现，OS频繁分配的小对象大小相对比较固定。所以我们可以从伙伴系统获得大块内存，将其进一步细分成固定大小的小块内存进行管理。块的大小一般设置为 $2^n$ 个字节( $3 \le n \le 12$ )，而且可以额外增加特殊大小如198字节从而减小内部碎片。

###（2）SLAB分配器的机制

我们将从伙伴系统获得的物理内存块称为slab，slab内部组织为空闲链表。SLAB分配器对不同的小块需求维护不同的内存资源池，每个内存资源池内有若干个slab，slab内被分成等长对应大小的小块。

<img src="图片\内存管理18.jpg" style="zoom:80%;" />

**内存池内的资源如何管理？**

维护三个指针：current, partial, full：

* current指针指向当下正在使用的slab，所有分配请求都将从该指针指向的slab中获得空闲的内存块。
* partial指针指向由所有包含空闲块的slab构成的链表。
* full指针指向所有块都耗尽的slab。

**具体分配与释放机制：**

分配：

* 当收到一个对小块的请求时，SLAB分配器首先为其匹配合适的内存资源池；然后从current指针下的slab中拿走一个空闲块即可。
* 如果current指向的slab已经满了，究竟将其移到full指针之下，并从partial指针下拿出一个空闲块返回即可。
* 如果partial指针指向为空，SLAB分配器会向回班系统申请新的物理内存作为新的slab。

释放：

* 当收到一个释放请求时，将被释放的块放回原本的slab空闲链表中即可。
* 如果原本的slab在移动之前处于full指针之下，释放块后移动至partial指针。
* 如果原本的slab本就只分配出一个块，也即释放之后空闲链表变为空，则可将此slab归还给伙伴系统。
